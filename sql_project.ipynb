{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def df_ify(series, scols):\n",
    "    sdict = series.to_dict()\n",
    "    smatrix = np.matrix([sdict.keys(),sdict.values()]).T\n",
    "    s = pd.DataFrame(data=smatrix)\n",
    "    s.columns = scols\n",
    "    return s\n",
    "\n",
    "## DATASETS/SQL SEARCHES\n",
    "\n",
    "#->searchers = datasets[\"users_who_searched\"]\n",
    "#   SELECT distinct(user_id) as searcher\n",
    "#   FROM tutorial.yammer_events  WHERE event_name like '%search_run%'\n",
    "\n",
    "#->search_events = datasets[\"count_search_events\"]  #print search_events.columns\n",
    "#   SELECT event_name, count(*) as cnt\n",
    "#   FROM tutorial.yammer_events \n",
    "#      where event_name like '%search%'\n",
    "#      GROUP BY event_name\n",
    "\n",
    "\n",
    "#->df = datasets[\"clicks_per_search\"]   #print df.columns\n",
    "#   SELECT all_search_clicks.user_id, \n",
    "#          all_search_clicks.event_name as click, \n",
    "#          all_search_clicks.occurred_at as clicktime,\n",
    "#          max(all_search_runs.occurred_at) as lastsearchtime\n",
    "#            FROM (SELECT * FROM tutorial.yammer_events AS events1 \n",
    "#                  WHERE events1.event_name like '%search_click%') as all_search_clicks\n",
    "#            JOIN (SELECT * FROM tutorial.yammer_events AS events2 \n",
    "#                  WHERE events2.event_name = 'search_run') as all_search_runs\n",
    "#             ON all_search_clicks.user_id = all_search_runs.user_id\n",
    "#             AND all_search_clicks.occurred_at > all_search_runs.occurred_at\n",
    "#             GROUP BY all_search_clicks.user_id, \n",
    "#                      all_search_clicks.event_name, \n",
    "#                      all_search_clicks.occurred_at\n",
    "#             ORDER BY all_search_clicks.user_id, \n",
    "#                      all_search_clicks.occurred_at, \n",
    "#                      all_search_clicks.event_name\n",
    "\n",
    "\n",
    "# gets all searches by user, consumated or not\n",
    "#->searches_and_users = datasets[\"searches_and_users\"] \n",
    "#   SELECT occurred_at as lastsearchtime,\n",
    "#          user_id,\n",
    "#          event_name as run\n",
    "#          FROM tutorial.yammer_events AS events2 \n",
    "#          WHERE events2.event_name = 'search_run'\n",
    "#          order by user_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "DISCUSSION\n",
    "A] Can we assign meaning to how often people use search?\n",
    "    1) If they hardly use it, it could indicate that it doesn't work well  \n",
    "        or that they don't need it because the site is so easy to navigate \n",
    "        or that they don't know it exists \n",
    "        or that they're not aware that it's applicable to their particular needs \n",
    "    2) Conversely, if they use it a lot, it could indicate that they like the functonality \n",
    "        or that the site is hard to navigate without it\"\n",
    "$  In either case, more context, such as what people are searching for, is needed for an evaluation\n",
    "\n",
    "\n",
    "B] Can we assign meaning to how often people stop searching at the autocomplete phase?\n",
    "    1) If they do so, it could mean that it's a good shortcut to search \n",
    "        - or that it's a way of browsing\"\n",
    "        - or that it's being used as an ad-hoc spellcheck\"\n",
    "        - or that it falsely gives the impression that a given search item will not be \n",
    "             found, leading people to give up\n",
    "        - or that it's laggy, causing the log to record an autocomplete that the user \n",
    "             didn't actually wait for\n",
    "$  Again, more context is needed for an evaluation\n",
    "\n",
    "\n",
    "C] Can we assign meaning to the number of searches that are consumated in a click?\n",
    "    1) If a search does not result in a click, it could mean that the user searched for an item\n",
    "            that doesn't exist\n",
    "        - or that the item does exist and search failed to find it\n",
    "        - or that search found it but that it was too deep in the results\n",
    "        - or that search found it but that the thumbnails in the results were not clear\n",
    "    2) If searches do result in clicks, however, it does become possible\n",
    "            to examine some of these questions.  \n",
    "        - A single click-through suggests that the item was found\n",
    "        - The depth of the click-through is visible, permitting an evaluation of search's\n",
    "            ability to bring relevant results to the top\n",
    "        - The number of click-throughs per search are visible, permitting an evaluation of\n",
    "            quality of thumbnail presentation\n",
    "$  Some of these questions can be approached by looking at the relationships between\n",
    "$  consumated searches and their associated clicks and by looking at the differences\n",
    "$  between consumated and non-consumated searches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "searchers = datasets[\"users_who_searched\"]\n",
    "print 'number of users who searched = ', len(searchers)\n",
    "\n",
    "search_events = datasets[\"count_search_events\"]  #print search_events.columns\n",
    "runs = search_events.loc[search_events['event_name'] == \"search_run\", 'cnt'].item()\n",
    "so_clicks = search_events[search_events.event_name.str.contains('click')]\n",
    "print 'number of searches = ', runs  #print 'number of clicks = ', sum(so_clicks['cnt'])\n",
    "\n",
    "\n",
    "df = datasets[\"clicks_per_search\"]   #print df.columns\n",
    "consumated_searches = df.groupby('lastsearchtime').click.nunique()\n",
    "\n",
    "print '\\nnumber of searches resulting in at least one click = ', len(consumated_searches)\n",
    "print '     % of searches resulting in at least one click = ', round(float(len(consumated_searches))/float(runs), 2) * 100\n",
    "avg =  (float(len(df))/float(len(consumated_searches)))\n",
    "print 'average clicks per consumated search =', round(avg,2)\n",
    "\n",
    "\n",
    "c = df_ify(series=consumated_searches, scols=['numsearches', 'numclicks'])\n",
    "cg = c.groupby('numclicks').count().reset_index()\n",
    "cg['numclicks'] = cg['numclicks'].astype('float')\n",
    "print \"\\ndistribution of consumated searches by number of clicks:\"\n",
    "print cg.sort_values('numclicks')\n",
    "print '*  People generally found what they wanted on the first click, ignoring'\n",
    "print '*  where in the search results that link was found.  This tells us that'\n",
    "print '*  the search result thumbnails are pretty good, though there\\'s room for improvement\\n'\n",
    "\n",
    "users_who_click = df.groupby('user_id').lastsearchtime.nunique()\n",
    "print ' average number of consumated searches  = ', round(users_who_click.mean(), 2)\n",
    "print '   fewest consumated searches by a user = ', users_who_click.min()\n",
    "print '     most consumated searches by a user = ', users_who_click.max()\n",
    "\n",
    "u = df_ify(series=users_who_click, scols=['num_users', 'num_consumated_searches'])\n",
    "ug = u.groupby('num_consumated_searches').count().reset_index()\n",
    "ug['num_consumated_searches'] = ug['num_consumated_searches'].astype('float')\n",
    "print \"\\ndistribution of users by number of consumated searches: \"\n",
    "print ug.sort_values('num_consumated_searches')\n",
    "print '*  Most people clicked through on a small number of searches '\n",
    "\n",
    "ratio_c_to_nonc = round(float(len(users_who_click))/float(len(searchers)), 2) * 100\n",
    "print '\\nnumber of users who\\'s searches were consumated =', len(users_who_click), '| %',ratio_c_to_nonc, 'of those who tried'\n",
    "print \"*  Roughly half of all people using the search functionalty never clicked through on a search.\"\n",
    "print \"*  It\\'s not that they stopped at the autocomplete phase.  They ran searches but never clicked\"\n",
    "print \"*  on any of the results. We don\\'t know if searches that were non-consumated were failures of search, \"\n",
    "print '*  or if the users were searching for something that wasn\\'t there,'\n",
    "print '*  but the even split between users who got something and those who got nothing at all'\n",
    "print '*  suggests that the way the search functonality works may not make sense for a large'\n",
    "print '*  number of people.  It may be that grouping search results by tabs is confusing\\n'\n",
    "\n",
    "searches_and_users = datasets[\"searches_and_users\"] # gets all searches by user, consumated or not\n",
    "merged = pd.merge(searches_and_users, df, left_on='lastsearchtime', right_on='lastsearchtime', how=\"outer\")\n",
    "\n",
    "# merged looks like this\n",
    "#\tlastsearchtime\t          run\t        user_id_x\t click\t   clicktime\t user_id_y\n",
    "#\t2014-06-19T15:08:05.000Z\tsearch_run\t4\t         NaN\t     NaN\t       NaN\n",
    "# 2014-05-27T15:10:06.000Z\tsearch_run\t4\t         result_6\t 2014-05..   4.0\n",
    "null_by_user = merged[merged.user_id_y.isnull()].user_id_x.value_counts()\n",
    "notnull_by_user = merged[merged.user_id_y.notnull()].user_id_x.value_counts()\n",
    "\n",
    "null_by_user.sort_index()\n",
    "notnull_by_user.sort_index()\n",
    "jj = pd.DataFrame(data=dict(notclicked=null_by_user, clicked=notnull_by_user)).fillna(0)\n",
    "jj['wholes'] = jj.notclicked + jj.clicked\n",
    "jj['successes'] = jj.clicked/jj.wholes\n",
    "\n",
    "savvy = jj[jj.clicked != 0] # drop the ones where the user never succeeded\n",
    "savvy_avg = round(savvy.successes.mean() * 100, 2)\n",
    "savvy_avg_attempts = round(savvy.wholes.mean())\n",
    "\n",
    "notsavvy = jj[jj.clicked == 0] \n",
    "notsavvy_avg_attempts = round(notsavvy.wholes.mean())\n",
    "\n",
    "\n",
    "print \"Those who ran searches and clicked through at least once:\"\n",
    "print \"  -> clicked through, on average,\", savvy_avg,\"percent of the time.\"\n",
    "print \"  -> attempted searches, on average,\", savvy_avg_attempts,\"times\"\n",
    "print \"Those who never clicked through:\"\n",
    "print \"  -> attempted searches, on average,\", notsavvy_avg_attempts,\"times\"\n",
    "print \"*  Being able to succeed in search roughly trippled the number of searches people did\"\n",
    "#users_who_search = df.groupby('user_id').lastsearchtime\n",
    "#users_who_search.head()\n",
    "\n",
    "print \"\\n#### distribution of depth of all clicks\"\n",
    "#print '\\n -- depth of the first click:'\n",
    "#print '-- distribution of depths of first click by user (across all clicks):'\n",
    "vc = df.click.value_counts().to_frame()\n",
    "vc['depth'] = vc.index.str.extract('(\\d+)', expand=False)\n",
    "vc['depth'] = vc['depth'].astype('float')\n",
    "print vc.sort_values('depth')\n",
    "\n",
    "all_first_clicks = df.groupby('lastsearchtime').nth(0)\n",
    "all_first_clicks['depth'] = all_first_clicks.click.str.extract('(\\d+)', expand=False)\n",
    "all_first_clicks['depth'] = all_first_clicks['depth'].astype('float')\n",
    "\n",
    "afc = all_first_clicks.groupby('user_id').mean()\n",
    "afc.reset_index(level=0, inplace=True)\n",
    "afc=afc.rename(columns = {'depth':'avg_depth'})\n",
    "avg_of_avges = str(round(afc.avg_depth.mean(), 2)) # average of the user averages of first click depths\n",
    "print \"\\n### average depth of first click per consumated search = \" + avg_of_avges\n",
    "\n",
    "# rounding averages to whole number to make distribution\n",
    "afc['avg_depth'] = afc['avg_depth'].astype('float')\n",
    "afc['avg_depth'] = afc['avg_depth'].round()\n",
    "avc = afc.avg_depth.value_counts()\n",
    "print \"### distribution of first click depths (not what one would expect)\"\n",
    "print avc\n",
    "##### quick visual inspection --- checks out\n",
    "#m = pd.merge(all_first_clicks, afc, left_on='user_id', right_on='user_id', how=\"outer\")\n",
    "#m.sort_values('user_id')\n",
    "#####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "number of users who searched =  2178\n",
    "number of searches =  13019\n",
    "\n",
    "number of searches resulting in at least one click =  3781\n",
    "     % of searches resulting in at least one click =  29.0\n",
    "average clicks per consumated search = 2.58\n",
    "\n",
    "#### distribution of consumated searches by number of clicks:\n",
    "   numclicks  numsearches\n",
    "0        1.0         2173\n",
    "2        2.0          608\n",
    "3        3.0          292\n",
    "4        4.0          237\n",
    "5        5.0          187\n",
    "6        6.0          130\n",
    "7        7.0           89\n",
    "8        8.0           37\n",
    "9        9.0           19\n",
    "1       10.0            9\n",
    "*  People generally found what they wanted on the first click, ignoring\n",
    "*  where in the search results that link was found.  This tells us that\n",
    "*  the search result thumbnails are pretty good, though there's room for improvement\n",
    "\n",
    "average number of consumated searches  =  3.24\n",
    "  fewest consumated searches by a user =  1\n",
    "    most consumated searches by a user =  20\n",
    "\n",
    "##### distribution of users by number of consumated searches: \n",
    "    num_consumated_searches  num_users\n",
    "0                       1.0        343\n",
    "1                       2.0        264\n",
    "2                       3.0        183\n",
    "3                       4.0        106\n",
    "4                       5.0         76\n",
    "5                       6.0         68\n",
    "6                       7.0         45\n",
    "7                       8.0         27\n",
    "8                       9.0         26\n",
    "9                      10.0          8\n",
    "10                     11.0         10\n",
    "11                     12.0          4\n",
    "12                     13.0          4\n",
    "13                     14.0          1\n",
    "14                     16.0          2\n",
    "15                     17.0          1\n",
    "16                     18.0          1\n",
    "17                     20.0          1\n",
    " \n",
    "##### distribution of first click depths (not what one would expect)\n",
    "4.0     272\n",
    "5.0     230\n",
    "6.0     191\n",
    "2.0     129\n",
    "3.0     127\n",
    "7.0      61\n",
    "1.0      51\n",
    "8.0      48\n",
    "9.0      39\n",
    "10.0     21\n",
    "*  Most people clicked through on a small number of searches \n",
    "\n",
    "##### number of users who's searches were consumated = 1170 | % 54.0 of those who tried\n",
    "*  Roughly half of all people using the search functionalty never clicked through on a search.\n",
    "*  It's not that they stopped at the autocomplete phase.  They ran searches but never clicked\n",
    "*  on any of the results. We don't know if searches that were non-consumated were failures of search, \n",
    "*  or if the users were searching for something that wasn't there,\n",
    "*  but the even split between users who got something and those who got nothing at all\n",
    "*  suggests that the way the search functonality works may not make sense for a large\n",
    "*  number of people.  It may be that grouping search results by tabs is confusing\n",
    "\n",
    "Those who ran searches and clicked through at least once:\n",
    "  -> clicked through, on average, 63.6 percent of the time.\n",
    "  -> attempted searches, on average, 13.0 times\n",
    "Those who never clicked through:\n",
    "  -> attempted searches, on average, 4.0 times\n",
    "*  Being able to succeed in search roughly trippled the number of searches people did\n",
    "\n",
    "##### distribution of depth of all clicks\n",
    "                        click  depth\n",
    "search_click_result_1    1412    1.0\n",
    "search_click_result_2    1496    2.0\n",
    "search_click_result_3    1133    3.0\n",
    "search_click_result_4    1264    4.0\n",
    "search_click_result_5     967    5.0\n",
    "search_click_result_6     805    6.0\n",
    "search_click_result_7     709    7.0\n",
    "search_click_result_8     690    8.0\n",
    "search_click_result_9     784    9.0\n",
    "search_click_result_10    506   10.0\n",
    "\n",
    "##### average depth of first click per consumated search = 4.65"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
