{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def df_ify(series, scols):\n",
    "    sdict = series.to_dict()\n",
    "    smatrix = np.matrix([sdict.keys(),sdict.values()]).T\n",
    "    s = pd.DataFrame(data=smatrix)\n",
    "    s.columns = scols\n",
    "    return s\n",
    "\n",
    "\n",
    "# -----------------------------     YAMMER INTERNAL SEARCH     -----------------------------\n",
    "\n",
    "## DATASETS/SQL SEARCHES\n",
    "\n",
    "# Who ran a search\n",
    "#->searchers = datasets[\"users_who_searched\"]\n",
    "    SELECT distinct(user_id) as searcher\n",
    "    FROM   tutorial.yammer_events  \n",
    "    WHERE event_name like '%search_run%'\n",
    "\n",
    "# Counting up all search like events to get an overall sense\n",
    "#->search_events = datasets[\"count_search_events\"]  \n",
    "    SELECT event_name, count(*) as cnt\n",
    "    FROM   tutorial.yammer_events \n",
    "    WHERE event_name like '%search%'\n",
    "    GROUP BY event_name\n",
    "\n",
    "# Establishing which clicks belong to which searches\n",
    "#->df = datasets[\"clicks_per_search\"] \n",
    "    SELECT  all_search_clicks.user_id, \n",
    "            all_search_clicks.event_name as click, \n",
    "            all_search_clicks.occurred_at as clicktime,\n",
    "            max(all_search_runs.occurred_at) as lastsearchtime\n",
    "                FROM (SELECT * FROM tutorial.yammer_events AS events1 \n",
    "                WHERE events1.event_name like '%search_click%') as all_search_clicks\n",
    "                    JOIN (SELECT * FROM tutorial.yammer_events AS events2 \n",
    "                                   WHERE events2.event_name = 'search_run') as all_search_runs\n",
    "                    ON all_search_clicks.user_id = all_search_runs.user_id\n",
    "                AND all_search_clicks.occurred_at > all_search_runs.occurred_at\n",
    "                GROUP BY all_search_clicks.user_id, \n",
    "                         all_search_clicks.event_name, \n",
    "                         all_search_clicks.occurred_at\n",
    "                ORDER BY all_search_clicks.user_id, \n",
    "                         all_search_clicks.occurred_at, \n",
    "                         all_search_clicks.event_name\n",
    "\n",
    "\n",
    "# Gets all searches by user, consumated or not\n",
    "#->searches_and_users = datasets[\"searches_and_users\"] \n",
    "    SELECT  occurred_at as lastsearchtime,\n",
    "            user_id,\n",
    "            event_name as run\n",
    "            FROM tutorial.yammer_events AS events2 \n",
    "            WHERE events2.event_name = 'search_run'\n",
    "            order by user_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#DISCUSSION\n",
    "#A] Can we assign meaning to how often people use search?\n",
    "#\n",
    "#    1) If they hardly use it, it could indicate that it doesn't work well  \n",
    "#        or that they don't need it because the site is so easy to navigate \n",
    "#        or that they don't know it exists \n",
    "#        or that they're not aware that it's applicable to their particular needs \n",
    "#\n",
    "#    2) Conversely, if they use it a lot, it could indicate that they like the functonality \n",
    "#        or that the site is hard to navigate without it\n",
    "#\n",
    "#  More context, such as what people are searching for, is needed for an evaluation\n",
    "#  of this question\n",
    "\n",
    "\n",
    "#B] Can we assign meaning to how often people stop searching at the autocomplete phase?\n",
    "#\n",
    "#    1) If they do so, it could mean that it's a good shortcut to search \n",
    "#        - or that it's a way of browsing\n",
    "#        - or that it's being used as an ad-hoc spellcheck\n",
    "#        - or that it falsely gives the impression that a given search item will not be \n",
    "#             found, leading people to give up\n",
    "#        - or that it's laggy, causing the log to record an autocomplete that the user \n",
    "#             didn't actually wait for\n",
    "#\n",
    "# Again, more context is needed for an evaluation\n",
    "\n",
    "\n",
    "#C] Can we assign meaning to the number of searches that are consumated in a click?\n",
    "#\n",
    "#    1) If a search does not result in a click, it could mean that the user searched for an item\n",
    "#            that doesn't exist\n",
    "#        - or that the item does exist and search failed to find it\n",
    "#        - or that search found it but that it was too deep in the results\n",
    "#        - or that search found it but that the thumbnails in the results were not clear\n",
    "#\n",
    "#    2) If searches do result in clicks, however, it does become possible to examine some \n",
    "#       of these questions.  \n",
    "#        - A single click-through suggests that the item was found\n",
    "#        - The depth of the click-through is visible, permitting an evaluation of search's\n",
    "#          ability to bring relevant results to the top\n",
    "#        - The number of click-throughs per search are visible, permitting an evaluation of\n",
    "#          quality of thumbnail presentation\n",
    "#        ... among other observatons that can be made\n",
    "#\n",
    "#  Some of these questions can be approached by looking at the relationships between\n",
    "#  consumated searches and their associated clicks and by looking at the differences\n",
    "#  between consumated and non-consumated searches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# users_who_searched provides a single column list of users\n",
    "searchers = datasets[\"users_who_searched\"]\n",
    "print 'number of users who searched = ', len(searchers)\n",
    "\n",
    "# search_events counts '%search%' like events. provides two columns [event_name] and [cnt]\n",
    "search_events = datasets[\"count_search_events\"] \n",
    "runs = search_events.loc[search_events['event_name'] == \"search_run\", 'cnt'].item()\n",
    "so_clicks = search_events[search_events.event_name.str.contains('click')]\n",
    "print 'number of searches = ', runs \n",
    "\n",
    "# df is a table that shows clicks and their associated searches\n",
    "#     user_id   click                    click_time             lastsearchtime\n",
    "#     4         search_click_result_6    2014-05-27 15:10:38    2014-05-27 15:10:06\n",
    "#     4         search_click_result_10   2014-05-27 15:10:57    2014-05-27 15:10:38\n",
    "#     4         search_click_result_2    2014-05-27 15:11:28    2014-05-27 15:11:01\n",
    "# where \"lastsearchtime\" is the timestamp of the search_run event that anchors\n",
    "# a given group of click events\n",
    "df = datasets[\"clicks_per_search\"]  \n",
    "consumated_searches = df.groupby('lastsearchtime').click.nunique()\n",
    "\n",
    "print 'number of searches resulting in at least one click = ', len(consumated_searches)\n",
    "pcent = (float(len(consumated_searches))/float(runs)) * 100\n",
    "print '     % of searches resulting in at least one click = ', rounc(pcent, 2)\n",
    "avg   = (float(len(df))/float(len(consumated_searches)))\n",
    "print '    average number of clicks per consumated search =', round(avg,2)\n",
    "\n",
    "\n",
    "# turning \"consumated_searches\" into a DF \n",
    "c = df_ify(series=consumated_searches, scols=['numsearches', 'numclicks'])\n",
    "cg = c.groupby('numclicks').count().reset_index()\n",
    "cg['numclicks'] = cg['numclicks'].astype('float')\n",
    "\n",
    "print \"distribution of consumated searches by number of clicks:\"\n",
    "print cg.sort_values('numclicks')\n",
    "print '*  People generally found what they wanted on the first click, ignoring'\n",
    "print '*  where in the search results that link was found.  This tells us that'\n",
    "print '*  the search result thumbnails are pretty good, though there\\'s room for improvement\\n'\n",
    "\n",
    "users_who_click = df.groupby('user_id').lastsearchtime.nunique()\n",
    "print ' average number of consumated searches  = ', round(users_who_click.mean(), 2)\n",
    "print '   fewest consumated searches by a user = ', users_who_click.min()\n",
    "print '     most consumated searches by a user = ', users_who_click.max()\n",
    "\n",
    "u = df_ify(series=users_who_click, scols=['num_users', 'num_consumated_searches'])\n",
    "ug = u.groupby('num_consumated_searches').count().reset_index()\n",
    "ug['num_consumated_searches'] = ug['num_consumated_searches'].astype('float')\n",
    "print \"distribution of users by number of consumated searches: \"\n",
    "print ug.sort_values('num_consumated_searches')\n",
    "print '*  Most people clicked through on a small number of searches, if at all '\n",
    "\n",
    "ratio_c_to_nonc = round(float(len(users_who_click))/float(len(searchers)), 2) * 100\n",
    "print 'number of users who clicked through on searches =', len(users_who_click), \n",
    "      '| %', ratio_c_to_nonc, 'of those who tried'\n",
    "print \"*  Roughly half of all people using the search '\n",
    "print '   functionalty never clicked through on a search.\"\n",
    "print \"*  It's not that they stopped at the autocomplete phase.  '\n",
    "print '   They ran searches but never clicked\"\n",
    "print \"*  on any of the results. We don't know if searches that were '\n",
    "print \"   non-consumated were failures of search, \"\n",
    "print '*  or if the users were searching for something that wasn\\'t there,'\n",
    "print '*  but the even split between users who got something and those who got nothing at all'\n",
    "print '*  suggests that the way the search functonality works may not make sense for a large'\n",
    "print '*  number of people.  It may be that grouping search results by tabs is confusing'\n",
    "\n",
    "searches_and_users = datasets[\"searches_and_users\"] # gets all searches by user, consumated or not\n",
    "merged = pd.merge(searches_and_users, df, left_on='lastsearchtime', right_on='lastsearchtime', how=\"outer\")\n",
    "\n",
    "# merged looks like this\n",
    "#   lastsearchtime              run          user_id_x   click      clicktime    user_id_y\n",
    "#   2014-06-19T15:08:05.000Z    search_run   4           NaN        NaN          NaN\n",
    "#   2014-05-27T15:10:06.000Z    search_run   4           result_6   2014-05..    4.0\n",
    "\n",
    "# These are, respectively, users who never succeeded in finding anything through search\n",
    "# and users who did sometimes find something\n",
    "null_by_user = merged[merged.user_id_y.isnull()].user_id_x.value_counts()\n",
    "notnull_by_user = merged[merged.user_id_y.notnull()].user_id_x.value_counts()\n",
    "\n",
    "null_by_user.sort_index()\n",
    "notnull_by_user.sort_index()\n",
    "jj = pd.DataFrame(data=dict(notclicked=null_by_user, clicked=notnull_by_user)).fillna(0)\n",
    "jj['wholes'] = jj.notclicked + jj.clicked\n",
    "jj['successes'] = jj.clicked/jj.wholes\n",
    "\n",
    "savvy = jj[jj.clicked != 0] # drop the ones where the user never succeeded\n",
    "savvy_avg = round(savvy.successes.mean() * 100, 2)\n",
    "savvy_avg_attempts = round(savvy.wholes.mean())\n",
    "\n",
    "notsavvy = jj[jj.clicked == 0] \n",
    "notsavvy_avg_attempts = round(notsavvy.wholes.mean())\n",
    "\n",
    "\n",
    "print \"Those who ran searches and clicked through at least once:\"\n",
    "print \"  -> clicked through, on average,\", savvy_avg,\"percent of the time.\"\n",
    "print \"  -> attempted searches, on average,\", savvy_avg_attempts,\"times\"\n",
    "print \"Those who never clicked through:\"\n",
    "print \"  -> attempted searches, on average,\", notsavvy_avg_attempts,\"times\"\n",
    "print \"*  Being able to succeed in search roughly trippled the number of searches people did\"\n",
    "\n",
    "print \"#### distribution of depth of all clicks\"\n",
    "vc = df.click.value_counts().to_frame()\n",
    "vc['depth'] = vc.index.str.extract('(\\d+)', expand=False)\n",
    "vc['depth'] = vc['depth'].astype('float')\n",
    "print vc.sort_values('depth')\n",
    "\n",
    "# making a list of people's first clicks\n",
    "all_first_clicks = df.groupby('lastsearchtime').nth(0)\n",
    "all_first_clicks['depth'] = all_first_clicks.click.str.extract('(\\d+)', expand=False)\n",
    "all_first_clicks['depth'] = all_first_clicks['depth'].astype('float')\n",
    "\n",
    "afc = all_first_clicks.groupby('user_id').mean()\n",
    "afc.reset_index(level=0, inplace=True)\n",
    "afc=afc.rename(columns = {'depth':'avg_depth'})\n",
    "\n",
    "# average of the user averages of first click depths\n",
    "avg_of_avges = str(round(afc.avg_depth.mean(), 2)) \n",
    "print \"\\n### average depth of first click per consumated search = \" + avg_of_avges\n",
    "\n",
    "# rounding averages to whole number to make distribution\n",
    "afc['avg_depth'] = afc['avg_depth'].astype('float')\n",
    "afc['avg_depth'] = afc['avg_depth'].round()\n",
    "avc = afc.avg_depth.value_counts()\n",
    "print \"### distribution of first click depths (not what one would expect)\"\n",
    "print avc\n",
    "\n",
    "##### quick visual inspection --- checks out\n",
    "#m = pd.merge(all_first_clicks, afc, left_on='user_id', right_on='user_id', how=\"outer\")\n",
    "#m.sort_values('user_id')\n",
    "#####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "|\n",
    "|  number of users who searched = 2178\n",
    "|  number of searches = 13019\n",
    "|\n",
    "\n",
    "|\n",
    "|  number of searches resulting in at least one click = 3781\n",
    "|       % of searches resulting in at least one click = 29.0\n",
    "|      average number of clicks per consumated search = 2.58\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "#  distribution of consumated searches by number of clicks:\n",
    "|\n",
    "|  numclicks  numsearches\n",
    "|        1.0         2173\n",
    "|        2.0          608\n",
    "|        3.0          292\n",
    "|        4.0          237\n",
    "|        5.0          187\n",
    "|        6.0          130\n",
    "|        7.0           89\n",
    "|        8.0           37\n",
    "|        9.0           19\n",
    "|        10.0           9\n",
    "|\n",
    "*  People generally found what they wanted on the first click, ignoring\n",
    "*  where in the search results that link was found.  This suggests that\n",
    "*  the search result thumbnails are ok, though there is room for improvement\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "| average number of consumated searches  = 3.24\n",
    "|   fewest consumated searches by a user = 1\n",
    "|     most consumated searches by a user = 20\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "#  distribution of users by number of consumated searches: \n",
    "|\n",
    "|  num_consumated_searches  num_users\n",
    "|                      1.0        343\n",
    "|                      2.0        264\n",
    "|                      3.0        183\n",
    "|                      4.0        106\n",
    "|                      5.0         76\n",
    "|                      6.0         68\n",
    "|                      7.0         45\n",
    "|                      8.0         27\n",
    "|                      9.0         26\n",
    "|                      10.0         8\n",
    "|                      11.0        10\n",
    "|                      12.0         4\n",
    "|                      13.0         4\n",
    "|                      14.0         1\n",
    "|                      16.0         2\n",
    "|                      17.0         1\n",
    "|                      18.0         1\n",
    "|                      20.0         1\n",
    "|\n",
    "*  Most people clicked through on a small number of searches, if at all \n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "|  number of users who clicked through on searches = 1170 | % 54.0 of those who tried\n",
    "|\n",
    "*  Roughly half of all people using the search functionalty never clicked through on a search.\n",
    "*  Its not that they stopped at the autocomplete phase.  They ran searches but never clicked\n",
    "*  on any of the results. We dont know if searches that were non-consumated were failures of \n",
    "*  search or if the users were searching for something that wasnt there,\n",
    "*  but the even split between users who got something and those who got nothing at all\n",
    "*  suggests that the way the search functonality works may not make sense for a large\n",
    "*  number of people.  It may be that grouping search results by tabs is confusing.\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "|  Those who ran searches and clicked through at least once:\n",
    "|     -> clicked through, on average, 63.6 percent of the time.\n",
    "|     -> attempted searches, on average, 13.0 times\n",
    "|  Those who never clicked through:\n",
    "|     -> attempted searches, on average, 4.0 times\n",
    "|\n",
    "*  Being able to succeed in search roughly trippled the number of searches people did\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "#  distribution of depth of all clicks\n",
    "|\n",
    "|                         clicks  depth\n",
    "|  search_click_result_1    1412    1.0\n",
    "|  search_click_result_2    1496    2.0\n",
    "|  search_click_result_3    1133    3.0\n",
    "|  search_click_result_4    1264    4.0\n",
    "|  search_click_result_5     967    5.0\n",
    "|  search_click_result_6     805    6.0\n",
    "|  search_click_result_7     709    7.0\n",
    "|  search_click_result_8     690    8.0\n",
    "|  search_click_result_9     784    9.0\n",
    "|  search_click_result_10    506   10.0\n",
    "|\n",
    "*  Broad distribution.  Not necessarily surprising if people search\n",
    "*  on 'Bob' or 'Alice' and the number of results is large.  More surprising if\n",
    "*  people search on 'Bob Pendergrass'.  Search contents would inform these\n",
    "*  numbers\n",
    "|\n",
    "\n",
    "\n",
    "|\n",
    "|  average depth of first click per consumated search = 4.65\n",
    "|\n",
    "#  distribution of first click depths \n",
    "|\n",
    "|  4.0     272\n",
    "|  5.0     230\n",
    "|  6.0     191\n",
    "|  2.0     129\n",
    "|  3.0     127\n",
    "|  7.0      61\n",
    "|  1.0      51\n",
    "|  8.0      48\n",
    "|  9.0      39\n",
    "|  10.0     21\n",
    "|\n",
    "*  Surprising.  Although by far the majority of searches that were followed\n",
    "*  by clicks were only followed by one click, that event is likely to be a few\n",
    "*  pages into the search.  \n",
    "*  Also, although I am not showing it here, as one looks at the average depth of \n",
    "*  the 2nd click, 3rd click and so on, the distribution of pages evens out. The\n",
    "*  impression is that people are flipping around, unsure where to click.\n",
    "|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
